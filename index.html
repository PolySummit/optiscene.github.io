<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>OptiScene & 3D-SynthPlace</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-widescreen">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization</h1>
            <h1 class="title is-3 publication-title">NeurIPS 2025</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Yixuan Yang<sup>1,3*</sup>,</span>
              <span class="author-block">Zhen Luo<sup>1,2*</sup>,</span>
              <span class="author-block">Tongsheng Ding<sup>1*</sup>,</span>
              <span class="author-block">Junru Lu<sup>3</sup>,</span>
              <span class="author-block">Mingqi Gao<sup>1</sup>,</span><br>
              <span class="author-block">Jinyu Yang<sup>4</sup>,</span>
              <span class="author-block">Victor Sanchez<sup>3</sup>,</span>
              <span class="author-block">Feng Zheng<sup>1†</sup></span>
            </div>

            <div class="is-size-5 publication-authors institution-list">
              <span class="author-block">1. Southern University of Science and Technology</span>&emsp;
              <span class="author-block">2. Shanghai Innovation Institute</span><br>
              <span class="author-block">3. University of Warwick</span>&emsp;
              <span class="author-block">4. Tapall.ai</span><br>
              <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution &nbsp; <sup>†</sup>Corresponding Author</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2506.07570" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                   <!-- Arxiv PDF link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->

              <!-- Supplementary PDF link
              <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Supplementary</span>
              </a>
            </span> -->

            <!-- Github link -->
            <span class="link-block">
              <a href="https://huggingface.co/datasets/B3rrYang/3D-SynthPlace_indoor_scenes_dataset" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Dataset</span>
            </a>
          </span>

          <span class="link-block">
            <a href="https://github.com/YOUR REPO HERE" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="fab fa-github"></i>
            </span>
            <span>Code (Coming Soon)</span>
          </a>
        </span>

          <!-- ArXiv abstract Link -->

      </div>
    </div>
  </div>
</div>
</section>


<!-- 顶部PDF图片替换视频 -->
<section class="hero teaser">
  <div class="container is-max-widescreen">
    <div class="hero-body">
      <img src="static/images/teaser_cropped.png" alt="Paper Cover" style="width:100%;max-width:1200px;display:block;margin:auto;">
      <h2 class="content">
        Overview of proposed <b>3D-SynthPlace</b> dataset and <b>OptiScene</b> framework for indoor layout generation.
        (Left): We propose 3D-SynthPlace, a large-scale, high-quality indoor layout dataset.
        (Middle): Our open-source LLM-based generator, OptiScene, takes user instructions and produces structured layout representations through a two-stage, coarse-to-fine optimization.
        (Right): OptiScene supports interactive layout editing and downstream tasks such as robotic navigation.
        (Bottom): Qualitative layout visualizations and quantitative comparisons show OptiScene's superior performance (success rate) over existing prompt-driven and learning-based baselines.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-widescreen">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Automatic indoor layout generation has attracted increasing attention due to its potential in interior design, virtual environment construction, and embodied AI.
            Existing methods fall into two categories: \textit{prompt-driven} approaches that leverage proprietary LLM services (e.g., GPT APIs), and \textit{learning-based} methods trained on layout data upon diffusion-based models.
            Prompt-driven methods often suffer from spatial inconsistency and high computational costs, while learning-based methods are typically constrained by coarse relational graphs and limited datasets, restricting their generalization to diverse room categories.
            In this paper, we revisit LLM-based indoor layout generation and present <b>3D-SynthPlace</b>, a large-scale dataset that combines synthetic layouts generated via a `GPT synthesize, Human inspect' pipeline, upgraded from the 3D-Front dataset. 3D-SynthPlace contains nearly 17,000 scenes, covering four common room types—bedroom, living room, kitchen, and bathroom—enriched with diverse objects and high-level spatial annotations.
            We further introduce <b>OptiScene</b>, a strong open-source LLM optimized for indoor layout generation, fine-tuned based on our 3D-SynthPlace dataset through our two-stage training.
            For the warum-up stage I, we adopt supervised fine-tuning (SFT), which is taught to first generate high-level spatial descriptions then conditionally predict concrete object placements. 
            For the reinforcing stage II, to better align the generated layouts with human design preferences, we apply multi-turn direct preference optimization (DPO), which significantly improving layout quality and generation success rates.
            Extensive experiments demonstrate that OptiScene outperforms traditional prompt-driven and learning-based baselines. Moreover, OptiScene shows promising potential in interactive tasks such as scene editing and robot navigation, highlighting its applicability beyond static layout generation.
            The dataset and the code will be released soon.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- 移动后的视频 -->
<section class="hero teaser">
  <div class="container is-max-widescreen">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End moved video -->




<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container has-text-centered">
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2> -->
      <!-- How OptiScene Works 图示 -->
<div style="text-align:center; margin-top: 2em;">
  <h2 style="text-align:center; font-weight:bold; letter-spacing:2px; font-size:1.5em;">
    How OptiScene works?
  </h2>
  <!-- <a href="static/images/how_optiscene_works.png" target="_blank"> -->
    <img src="static/images/main_cropped.png" alt="How OptiScene Works?" style="max-width:100%; height:auto; margin-top:1em;">
  <!-- </a>   -->
</div>

<!-- Data distribution analysis 图示 -->
<div style="text-align:center; margin-top: 2em;">
  <h2 style="font-weight:bold; text-align:center; font-size:1.5em;">
    Data distribution analysis of 3D-SynthPlace.
  </h2>
  <!-- <a href="static/images/dataset.pdf" target="_blank"> -->
    <img src="static/images/dataset.png" alt="Data distribution analysis of 3D-SynthPlace" style="max-width:100%; height:auto; margin-top:1em;">
  <!-- </a> -->
</div>
    </div>
  </div>
</section>
<!-- Results -->
<div style="text-align:center; margin:auto; margin-top: 2em;", class="container is-max-widescreen">
  <h2 style="font-weight:bold; text-align:center; font-size:1.5em;">
    Quantitative comparison with other methods
  </h2>
    <h2 class="content; text-align:left;">
      Comparison with [FID ↓ / OOR ↓] across 3D-Front \& 3D-SynthPlace.
    </h2>
  <!-- <a href="static/images/Q1result.jpg" target="_blank"> -->
    <img src="static/images/Q1result.jpg" alt="Quantitative comparison with other methods" style="max-width:100%; height:auto; margin-top:1em;">
  <!-- </a> -->
</div>

<div style="text-align:center; margin:auto; margin-top: 2em;", class="container is-max-widescreen">

    <h2 class="content; text-align:left;">
      Comparison with GPT-[Func ↑ / Layout ↑ /Aes. ↑] on 3D-Front \& 3D-SynthPlace.
    </h2>
  <!-- <a href="static/images/Q2result.jpg" target="_blank"> -->
    <img src="static/images/Q2result.jpg" alt="Quantitative comparison with other methods" style="max-width:100%; height:auto; margin-top:1em;">
  <!-- </a> -->
</div>

<div style="text-align:center; margin:auto; margin-top: 2em;", class="container is-max-widescreen">
  <h2 style="font-weight:bold; text-align:center; font-size:1.5em;">
    Qualitative comparison with other methods.
  </h2>
    <h2 class="content; text-align:left;">

    </h2>
  <!-- <a href="static/images/Q1result.jpg" target="_blank"> -->
    <img src="static/images/quan_results.png" alt="Qualitative comparison with other methods" style="max-width:100%; height:auto; margin-top:1em;">
  <!-- </a> -->
</div>

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h2 style="font-weight:bold; text-align:center; font-size:1.5em;">
        More qualitative results.
      </h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/moreresult1_cropped.png" alt="MY ALT TEXT"/>

      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/moreresult2_cropped.png" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          Second image description.
        </h2> -->
      </div>
</div>
</div>
</section>




<!-- End image carousel -->





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-widescreen content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{yang2025llm,
        title={LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization},
        author={Yang, Yixuan and Luo, Zhen and Ding, Tongsheng and Lu, Junru and Gao, Mingqi and Yang, Jinyu and Sanchez, Victor and Zheng, Feng},
        journal={arXiv preprint arXiv:2506.07570},
        year={2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
